{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I am optimus prime from Cybetron.', 'I am one of the dangerous guy']\n",
      "[['I', 'am', 'optimus', 'prime', 'from', 'Cybetron', '.'], ['I', 'am', 'one', 'of', 'the', 'dangerous', 'guy']]\n"
     ]
    }
   ],
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "import nltk\n",
    "\n",
    "# Tockenizing Text\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "words = []\n",
    "text = \"I am optimus prime from Cybetron. I am one of the dangerous guy\"\n",
    "sents = sent_tokenize(text)\n",
    "print(sents)\n",
    "words = [word_tokenize(sent) for sent in sents]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"you're\", 'she', 'm', 'ourselves', 'from', \"it's\", 'o', 'her', '(', '^', 'any', 'through', 'or', ',', 'but', 'just', 'this', 'nor', '+', \"you've\", \"couldn't\", 'yourselves', 'for', \"doesn't\", 'hasn', '=', 'he', 's', 'on', 'who', 'against', 'where', 'whom', 'should', \"mightn't\", 'y', '@', 'above', '%', 'itself', 'doing', '_', 've', 'your', \"won't\", 'myself', 'haven', \"hadn't\", 'having', 'once', 'after', 'more', '*', 'until', 'weren', 'not', 'have', 'own', 'only', 'an', 'as', 'these', 'in', 'each', \"don't\", 'mustn', 'is', 'was', 'further', 'mightn', 'a', 'you', 'they', \"you'll\", 'few', 'we', 'shan', 'under', '\\\\', 'has', '.', '[', 'aren', 'during', 'why', 'how', 're', 'because', \"haven't\", '}', 'which', 'here', \"you'd\", 'd', '!', '|', 'won', 'his', \"she's\", 'while', 'most', 'other', 'the', 'then', 'needn', \"isn't\", 'my', 'doesn', 'ain', \"needn't\", 'and', '?', 'those', 'below', 'before', 'are', 'off', '/', 'too', 'into', '~', 'hers', \"mustn't\", 'me', 'very', 'no', \"hasn't\", '&', \"didn't\", 'that', 'can', 'between', 'again', 'hadn', 'didn', \"wasn't\", 'by', 't', ';', 'had', 'does', '$', \"wouldn't\", '-', 'such', \"should've\", 'down', 'ours', 'herself', 'now', '`', 'of', 'isn', 'being', '#', 'wasn', '<', 'to', 'him', 'both', 'will', 'yours', \"shan't\", 'been', 'up', 'couldn', ']', 'himself', 'at', 'am', 'our', 'about', 'same', 'be', ':', 'themselves', \"weren't\", 'did', 'wouldn', 'yourself', 'it', 'out', 'll', 'i', ')', 'what', 'them', 'were', 'do', '\"', 'with', \"aren't\", 'if', 'their', \"'\", 'its', 'than', 'all', 'so', 'when', \"shouldn't\", 'don', 'over', 'there', 'theirs', 'shouldn', '>', '{', 'ma', \"that'll\", 'some'}\n"
     ]
    }
   ],
   "source": [
    "# Stopword Elimination\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "customStopWords = set(stopwords.words('english') + list (punctuation))\n",
    "print(customStopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'optimus', 'prime', 'Cybetron', 'I', 'one', 'dangerous', 'guy']\n"
     ]
    }
   ],
   "source": [
    "customizedTextWords= [word for word in word_tokenize(text) if word not in customStopWords]\n",
    "print(customizedTextWords)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(('I', 'optimus'), 1), (('optimus', 'prime'), 1), (('prime', 'Cybetron'), 1), (('Cybetron', 'I'), 1), (('I', 'one'), 1), (('one', 'dangerous'), 1), (('dangerous', 'guy'), 1)])\n"
     ]
    }
   ],
   "source": [
    "# Identifying Bigrames\n",
    "from nltk.collocations import *\n",
    "\n",
    "biagrams_measures = nltk.collocations.BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_words(customizedTextWords)\n",
    "print(finder.ngram_fd.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(('I', 'optimus', 'prime'), 1), (('optimus', 'prime', 'Cybetron'), 1), (('prime', 'Cybetron', 'I'), 1), (('Cybetron', 'I', 'one'), 1), (('I', 'one', 'dangerous'), 1), (('one', 'dangerous', 'guy'), 1)])\n"
     ]
    }
   ],
   "source": [
    "# Identifying Trigrames\n",
    "\n",
    "biagrams_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "finder = TrigramCollocationFinder.from_words(customizedTextWords)\n",
    "print(finder.ngram_fd.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'am', 'optim', 'prim', 'from', 'cybetron', '.', 'i', 'am', 'on', 'of', 'the', 'dang', 'guy']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('am', 'VBP'),\n",
       " ('optimus', 'JJ'),\n",
       " ('prime', 'JJ'),\n",
       " ('from', 'IN'),\n",
       " ('Cybetron', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('am', 'VBP'),\n",
       " ('one', 'CD'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('dangerous', 'JJ'),\n",
       " ('guy', 'NN')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemming and POS Tagging\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "st = LancasterStemmer()\n",
    "stemmedWords = [st.stem(word) for word in word_tokenize(text)]\n",
    "print(stemmedWords)\n",
    "nltk.pos_tag(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('sing.v.01') deliver by singing\n",
      "Synset('sing.v.02') produce tones with the voice\n",
      "Synset('sing.v.03') to make melodious sounds\n",
      "Synset('whistle.v.05') make a whining, ringing, or whistling sound\n",
      "Synset('spill_the_beans.v.01') divulge confidential information or secrets\n"
     ]
    }
   ],
   "source": [
    "# Disambiguting word meaning\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "for ss in wn.synsets('sing'):\n",
    "    print(ss, ss.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('dangerous.s.02') causing fear or anxiety by threatening great harm\n"
     ]
    }
   ],
   "source": [
    "from nltk.wsd import lesk\n",
    "\n",
    "sen1 = lesk(word_tokenize(text),'dangerous')\n",
    "print(sen1, sen1.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('dangerous.a.01') involving or causing danger or risk; liable to hurt or harm\n"
     ]
    }
   ],
   "source": [
    "sen2 = lesk(word_tokenize(\"lion is a danger animal\"),'dangerous')\n",
    "print(sen2, sen2.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
