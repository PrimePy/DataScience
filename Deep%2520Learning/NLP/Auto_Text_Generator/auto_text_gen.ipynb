{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled15.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPJ41zNYV+H/ygWI1VzZdlN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PrimePy/DataScience/blob/master/Deep%252520Learning/NLP/Auto_Text_Generator/auto_text_gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSj-YTRPCsv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Libs\n",
        "import tensorflow as tf\n",
        "import requests\n",
        "import string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTfe-Y7vDEM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read the data\n",
        "response = requests.get('https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt')\n",
        "data = response.text.split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m_a079hDN4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove header from the text file\n",
        "data = data[253:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLckzZ2BDRoE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clean the text data\n",
        "data = ' '.join(data)\n",
        "\n",
        "def clean_text(doc):\n",
        "    tokens = data.split()\n",
        "    punc = str.maketrans('', '', string.punctuation)\n",
        "    tokens = [word.translate(punc) for word in tokens]\n",
        "    tokens = [ word.lower() for word in tokens if word.isalpha()]\n",
        "    return tokens\n",
        "\n",
        "cleaned_tokens = clean_text(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PF1_BJolDUS7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert tokens into sequence\n",
        "seq_length = 50 + 1\n",
        "sequences = []\n",
        "\n",
        "for index in range(seq_length, len(cleaned_tokens)):\n",
        "    line = ' '.join(cleaned_tokens[(index - seq_length) : index])\n",
        "    sequences.append(line) \n",
        "    if index > 200000:\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBp2pytqDm1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build LSTM model and Preprocess input and output data\n",
        "        \n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sequences)\n",
        "tokenized_sequences = tokenizer.texts_to_sequences(sequences)\n",
        "tokenized_sequences = np.array(tokenized_sequences[:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqDALrdVFWIp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "53abb9bd-a626-4818-dd20-f8e363f23d74"
      },
      "source": [
        "# Initialize the x and y\n",
        "x, y = tokenized_sequences[:, :-1], tokenized_sequences[:, -1]\n",
        "\n",
        "# Initialize the vocabulary size\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Covert y into categorical\n",
        "y = to_categorical(y, num_classes= vocab_size)\n",
        "\n",
        "# Initialize the sequence length\n",
        "seq_length = len(x[0])\n",
        "print(len(x[0]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRAH-493FiCJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "ac1edc11-d41c-441a-a4fb-c9a07f7bfab7"
      },
      "source": [
        "# Create LSTM Model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 50, input_length = seq_length))\n",
        "model.add(LSTM(100, return_sequences = True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation = 'relu'))\n",
        "model.add(Dense(vocab_size, activation = 'softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 50, 50)            1350      \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 50, 100)           60400     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 27)                2727      \n",
            "=================================================================\n",
            "Total params: 154,977\n",
            "Trainable params: 154,977\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gd57LnzgFuiv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile LSTM Model\n",
        "model.compile( loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_31FoKYGyJ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "84aaf249-b120-457c-e8ff-222e82e1c1c1"
      },
      "source": [
        "# Train LSTM Model\n",
        "model.fit(x, y, batch_size = 256, epochs = 100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "665/782 [========================>.....] - ETA: 48s - loss: 2.7059 - accuracy: 0.1836"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MA7ca4xDGzwl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dgnhqe5HJQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}